{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aplicación de análisis del caso\n",
    "\n",
    "Para casos con una sola columna de respuestas.\n",
    "Casos disponibles:\n",
    "- Luis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "caso = \"Luis 2023\"\n",
    "resultados_img = f\"../resultados/{caso}/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guardar datos del caso por sección"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caso seleccionado: Luis 2023\n",
      "Archivo: Procesamient_2023_Luis.xlsx, Año: 2023\n",
      "\n",
      "Carpeta creada: processed_data/Luis 2023\n",
      "Datos procesados guardados en: processed_data/Luis 2023/answers_by_secc_Luis 2023.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os \n",
    "import warnings\n",
    "\n",
    "# Ignorar advertencias específicas de openpyxl\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"openpyxl\")\n",
    "\n",
    "print(f\"Caso seleccionado: {caso}\")\n",
    "\n",
    "# PATH a las carpetas de datos\n",
    "ANSWERS_DATA_PATH = f'../data/answers/{caso}'\n",
    "FOLDERS_ANSWERS = os.listdir(ANSWERS_DATA_PATH)\n",
    "\n",
    "# Dataframe para almacenar los datos\n",
    "df_answers = pd.DataFrame(columns=['Respuesta', 'agno'])\n",
    "\n",
    "# Leer archivos excel del directorio y extraer agno y seccion\n",
    "for file in FOLDERS_ANSWERS:\n",
    "    parts = file.split('_')  \n",
    "    if len(parts) >= 3: \n",
    "        agno = parts[1]  \n",
    "        print(f\"Archivo: {file}, Año: {agno}\")\n",
    "    else:\n",
    "        print(f\"==== Error en extracción de año para el archivo: {file} ====\")\n",
    "        agno = None\n",
    "    \n",
    "    # Extracción de columnas\n",
    "    df = pd.read_excel(f'{ANSWERS_DATA_PATH}/{file}', sheet_name='Datos')\n",
    "    df = df[['Respuesta']]\n",
    "    \n",
    "    # Añadir columnas de agno\n",
    "    df['agno'] = agno\n",
    "    \n",
    "    df_answers = pd.concat([df_answers, df], ignore_index=True)\n",
    "\n",
    "# Sort, fillna y convertir columnas a string\n",
    "df_answers.sort_values(by=['Respuesta', 'agno'], inplace=True)\n",
    "df_answers.fillna('', inplace=True)\n",
    "\n",
    "# Convertir las columnas especificadas a tipo string\n",
    "columnas_a_convertir = [\n",
    "    'Respuesta'\n",
    "]\n",
    "\n",
    "# Convertir las columnas a string\n",
    "for columna in columnas_a_convertir:\n",
    "    df_answers[columna] = df_answers[columna].astype(str)\n",
    "\n",
    "# Ruta para almacenar los datos procesados\n",
    "folder_path = f'processed_data/{caso}'\n",
    "\n",
    "# Verificar si la carpeta existe, y si no, crearla\n",
    "if not os.path.exists(folder_path):\n",
    "    os.makedirs(folder_path)\n",
    "    print(f\"\\nCarpeta creada: {folder_path}\")\n",
    "else:\n",
    "    print(f\"\\nCarpeta ya existe: {folder_path}\")\n",
    "\n",
    "# Guardar datos como un nuevo csv en una ruta\n",
    "df_answers.to_csv(f'../{folder_path}/answers_by_secc_{caso}.csv', index=False)\n",
    "print(f\"Datos procesados guardados en: {folder_path}/answers_by_secc_{caso}.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cargar conjunto de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "folder_path = f'processed_data/{caso}'\n",
    "df_caso = pd.read_csv(f'../{folder_path}/answers_by_secc_{caso}.csv', sep=',')\n",
    "\n",
    "# Reducir a 20 filas\n",
    "#df_caso = df_caso.head(20).sort_values(by=['agno', 'seccion', 'Grup'])\n",
    "\n",
    "df_caso = df_caso.sort_values(by=['agno'])\n",
    "df_caso = df_caso.fillna('')\n",
    "\n",
    "# Columnas con respuestas\n",
    "columnas_a_convertir = [\n",
    "    'Respuesta'\n",
    "]\n",
    "\n",
    "# Convertir las columnas a string\n",
    "for columna in columnas_a_convertir:\n",
    "    df_caso[columna] = df_caso[columna].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análisis Gramatical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# Importar las funciones del archivo software.py ubicado en la carpeta software_development\n",
    "import sys\n",
    "sys.path.append('../utils')\n",
    "from model__1 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aplicar_dependencias_grupal(df):\n",
    "    df['Dependencias'] = df['Respuesta'].apply(lambda x: analizar_dependencias(str(x)))\n",
    "    \n",
    "    df.to_csv(f\"../processed_data/{caso}/Tree_dependency_df.csv\", index=False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aplicar y guardar análisis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar la función optimizada a ambos DataFrames\n",
    "Tree_Dependency_d1 = aplicar_dependencias_grupal(df_caso)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gráficos de analisis gramatical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================== GRAFICOS ============================================== #\n",
    "plt.style.use('fivethirtyeight')  \n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Datos para el boxplot\n",
    "data_d1 = [Tree_Dependency_d1['Dependencias']]\n",
    "labels = ['Año 2023']\n",
    "positions_d1 = [1]  # Posición para el diferencial 1\n",
    "\n",
    "# Crear boxplot para diferencial 1\n",
    "boxplot_d1 = plt.boxplot(\n",
    "    data_d1,\n",
    "    positions=positions_d1,\n",
    "    widths=0.6,\n",
    "    patch_artist=True,\n",
    "    boxprops=dict(facecolor='lightblue', color='blue'),\n",
    "    whiskerprops=dict(color='blue'),\n",
    "    capprops=dict(color='blue'),\n",
    "    medianprops=dict(color='darkblue'),\n",
    "    flierprops=dict(markeredgecolor='blue')\n",
    ")\n",
    "\n",
    "# Etiquetas y formato\n",
    "plt.xticks(positions_d1, labels)\n",
    "plt.ylabel('Dependencias')\n",
    "plt.title(f'Caso: {caso} - Oraciones subordinadas por etapa y diferencial', fontsize=16, pad=20, fontfamily='serif')\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Información adicional (si aplica)\n",
    "total_alumnos_d1 = Tree_Dependency_d1.shape[0]\n",
    "plt.figtext(\n",
    "    0.5, -0.05, \n",
    "    f'Estudiantes analizados: {total_alumnos_d1}', \n",
    "    ha='center', fontsize=10\n",
    ")\n",
    "\n",
    "# Guardar gráfico\n",
    "plt.savefig(f\"{resultados_img}/Analisis_Gramatical_boxplot_dependencias.png\", bbox_inches='tight')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análisis de topicos BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Procesar comentarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import spacy\n",
    "import pandas as pd\n",
    "from nltk.stem import SnowballStemmer\n",
    "from bertopic import BERTopic\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================ TOKENIZADOR ============================ #\n",
    "nlp = spacy.load('es_core_news_md')\n",
    "\n",
    "# Función para cargar las stopwords\n",
    "def cargar_stopwords(ruta_archivo):\n",
    "    try:\n",
    "        with open(ruta_archivo, 'r', encoding='utf-8') as f:\n",
    "            return set(f.read().splitlines())\n",
    "    except FileNotFoundError:\n",
    "        print(f\"El archivo {ruta_archivo} no se encontró. Usando un conjunto vacío.\")\n",
    "        return set()\n",
    "\n",
    "global stop_words_custom\n",
    "stop_words_custom = cargar_stopwords('../dictionaries/stopwords_es.txt')\n",
    "\n",
    "# Clase para tokenización y stemming/lemmatización\n",
    "class StemmerTokenizer:\n",
    "    def __init__(self, stem=False, lemmatize=True):\n",
    "        self.stem = stem\n",
    "        self.lemmatize = lemmatize\n",
    "        self.ps = SnowballStemmer('spanish') if stem else None\n",
    "        self.stop_words_custom = cargar_stopwords('../dictionaries/stopwords_es.txt')\n",
    "\n",
    "    def __call__(self, doc):\n",
    "        # Limpiar y procesar el texto\n",
    "        doc = re.sub(r'[^A-Za-záéíóúñÁÉÍÓÚÑ\\s]', '', doc).lower()\n",
    "        spacy_doc = nlp(doc)\n",
    "        tokens = [\n",
    "            self.ps.stem(token.lemma_) if self.stem and self.ps else token.lemma_\n",
    "            for token in spacy_doc \n",
    "            if token.text not in self.stop_words_custom and not token.is_punct\n",
    "        ]\n",
    "        return tokens\n",
    "\n",
    "# Inicializar el tokenizador\n",
    "tokenizer = StemmerTokenizer(stem=False, lemmatize=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================================== PROCESAR COMENTARIOS ===================================================== #\n",
    "columnas_comentarios_dif1 = [\n",
    "    'Respuesta'\n",
    "]\n",
    "\n",
    "\n",
    "# Concatenar los comentarios de las columnas seleccionadas de ambos DataFrames\n",
    "comentarios_dif1 = df_caso[columnas_comentarios_dif1].fillna('').values.flatten()\n",
    "\n",
    "# Unir todos los comentarios en un solo array\n",
    "comentarios = pd.concat([pd.Series(comentarios_dif1)], axis=0).values.flatten()\n",
    "comentarios = [str(c) for c in comentarios]\n",
    "comentarios_tokenizados = [' '.join(tokenizer(c)) for c in comentarios]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-17 00:11:33,506 - BERTopic - WARNING: When you use `pickle` to save/load a BERTopic model,please make sure that the environments in which you saveand load the model are **exactly** the same. The version of BERTopic,its dependencies, and python need to remain the same.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tópicos más importantes:\n",
      "Tópico 0: -1_luis_proyecto_deber_él\n",
      "Tópico 1: 0_luis_jefe_él_empresa\n",
      "Tópico 2: 1_deber_luis_empresa_proyecto\n",
      "Tópico 3: 2_título_chile_honestidad_ingeniero\n",
      "Tópico 4: 3_riesgo_situación_falta_seguridad\n",
      "Tópico 5: 4_prueba_deber_consecuencia_seguro\n",
      "Tópico 6: 5_deber_proyecto_luis_producto\n",
      "Tópico 7: 6_chip_deber_ciudad_presa\n",
      "Tópico 8: 7_proyecto_desarrollo_falta_empresa\n",
      "Tópico 9: 8_colega_unir_sobreponer_categoría\n",
      "Largo de los tópicos: 10\n"
     ]
    }
   ],
   "source": [
    "# ===================================================== ENTRENAMIENTO MODELO ===================================================== #\n",
    "model = BERTopic(language=\"spanish\", min_topic_size=3, nr_topics=10)\n",
    "topics, probs = model.fit_transform(comentarios_tokenizados)\n",
    "model.save(\"../saved_models/BertTopic_model_Luis\")\n",
    "\n",
    "print(\"Tópicos más importantes:\")\n",
    "for i, topic in enumerate(model.get_topic_info().head(20)['Name']):\n",
    "    print(f\"Tópico {i}: {topic}\")\n",
    "\n",
    "print(\"Largo de los tópicos:\", len(model.get_topic_info()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================================== PREDICCIÓN TÓPICOS ===================================================== #\n",
    "BERT_model = BERTopic.load(\"../saved_models/BertTopic_model_Luis\")\n",
    "\n",
    "# Extraer tópicos para cada etapa (Ind1, Grup, Ind2)\n",
    "topics_ind1_dif1 = model.transform(df['Respuesta'].values.flatten())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar los tópicos en los dataframes\n",
    "BERT_df1 = df_caso.copy()\n",
    "\n",
    "BERT_df1['BERT_topicos_ind1'] = topics_ind1_dif1\n",
    "# Guardar como csv\n",
    "BERT_df1.to_csv(f\"../processed_data/{caso}/BERT_df1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graficos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para contar tópicos en una lista de comentarios\n",
    "def contar_topicos(topics):\n",
    "    topic_counts = Counter(topics)\n",
    "    return topic_counts\n",
    "\n",
    "# Contar la frecuencia de tópicos en cada grupo\n",
    "topic_counts_ind1_dif1 = contar_topicos(topics_ind1_dif1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generando gráfico de Frencuencia de Tópicos por Etapa...\n",
      "Gráfico generado exitosamente.\n",
      "Generando gráficos de tópicos más y menos comunes...\n",
      "Gráficos generados exitosamente.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "def graficar_topicos_agrupados(topic_counts_ind1):\n",
    "    all_topics = set(topic_counts_ind1.keys())\n",
    "    \n",
    "    filtered_topics = [\n",
    "        topic for topic in all_topics \n",
    "        if (topic_counts_ind1.get(topic, 0))\n",
    "    ]\n",
    "\n",
    "    top_words = []\n",
    "    for topic in filtered_topics:\n",
    "        try:\n",
    "            top_words.append(\", \".join([w[0] for w in model.get_topic(topic)[:5]]))\n",
    "        except:\n",
    "            top_words.append(f\"Tópico {topic} no encontrado\")\n",
    "\n",
    "    freqs_ind1 = [topic_counts_ind1.get(topic, 0) for topic in filtered_topics]\n",
    "\n",
    "    x = range(len(filtered_topics))\n",
    "    print(f\"Generando gráfico de Frencuencia de Tópicos por Etapa...\")\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    width = 0.2\n",
    "    bars_ind1 = plt.bar([p - width for p in x], freqs_ind1, width=width, label='Ind1', color=sns.color_palette(\"Blues\")[2])\n",
    "\n",
    "    plt.xlabel('Tópicos (Palabras Clave)', fontsize=14)\n",
    "    plt.ylabel('Frecuencia', fontsize=14)\n",
    "    plt.title(f\"Caso: {caso} - Frecuencia de Tópicos BERT\", fontsize=16, fontfamily='serif', pad=20, fontweight='bold')\n",
    "    plt.xticks(ticks=x, labels=top_words, rotation=90, fontsize=12)\n",
    "    plt.legend(fontsize=12, loc='upper right')\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    \n",
    "    # Añadir porcentajes a las barras\n",
    "    alumnos_totales = df_caso.shape[0]\n",
    "    for bar, freq, total_alumnos in zip(bars_ind1, freqs_ind1, [alumnos_totales]*len(filtered_topics)):\n",
    "        porcentaje = freq * 100 / total_alumnos if total_alumnos > 0 else 0\n",
    "        plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 0.5, f\"{porcentaje:.1f}%\", \n",
    "                    ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.figtext(0.5, -0.05, f'Estudiantes {alumnos_totales}', \n",
    "            ha='center', fontsize=12)\n",
    "    plt.savefig(f\"{resultados_img}/BERT_frec_topicos_d.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "    print(\"Gráfico generado exitosamente.\")\n",
    "    # ==== GRAFICO TOPICOS MAS COMUNES ==== #\n",
    "    # Top 10 topicos mas frecuentes (considerando todas las etapas y distinguiendo por diferencial)\n",
    "    total_counts = {topic: (topic_counts_ind1.get(topic, 0)) \n",
    "                for topic in filtered_topics}\n",
    "\n",
    "    top_10_topics = sorted(total_counts.items(), key=lambda x: x[1], reverse=True)[:10]\n",
    "    top_10_topics, top_10_freqs = zip(*top_10_topics)\n",
    "    bottom_20_topics = sorted(total_counts.items(), key=lambda x: x[1])[:20]\n",
    "    bottom_20_topics, bottom_20_freqs = zip(*bottom_20_topics)\n",
    "\n",
    "    top_words = []\n",
    "    for topic in filtered_topics:\n",
    "        try:\n",
    "            top_words.append(\", \".join([w[0] for w in model.get_topic(topic)[:5]]))\n",
    "        except:\n",
    "            top_words.append(f\"Tópico {topic} no encontrado\")\n",
    "    \n",
    "    top_10_words = [\", \".join([w[0] for w in model.get_topic(topic)[0:5]]) for topic in top_10_topics]\n",
    "    bottom_20_words = [\", \".join([w[0] for w in model.get_topic(topic)[0:5]]) for topic in bottom_20_topics]\n",
    "\n",
    "    palette = ['#ADD8E6', '#B0E0E6', '#87CEEB', '#87CEFA', '#4682B4']\n",
    "\n",
    "    print(f\"Generando gráficos de tópicos más y menos comunes...\")\n",
    "    # Graficar los 10 tópicos más comunes\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    ax = sns.barplot(x=list(top_10_freqs), y=list(top_10_words), palette=palette)\n",
    "        \n",
    "    plt.ylabel('Tópicos (Palabras Clave)', fontsize=14)\n",
    "    plt.xlabel('Frecuencia', fontsize=14)\n",
    "    plt.title(f\"Caso: {caso} - Top tópicos más comunes\", \n",
    "            fontsize=16, fontfamily='serif', pad=20, fontweight='bold')\n",
    "    plt.grid(axis='x', linestyle='--', alpha=0.7)\n",
    "    plt.tight_layout()\n",
    "    plt.figtext(0.5, -0.05, f'Estudiantes: {total_alumnos} | Respuestas: {total_alumnos}', \n",
    "            ha='center', fontsize=12)\n",
    "    plt.savefig(f\"{resultados_img}/BERT_Top10_Topicos_Mas_Comunes_d.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "    # Graficar los 20 tópicos menos comunes\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    sns.barplot(x=list(bottom_20_freqs), y=list(bottom_20_words), palette=palette)\n",
    "    plt.ylabel('Tópicos (Palabras Clave)', fontsize=14)\n",
    "    plt.xlabel('Frecuencia', fontsize=14)\n",
    "    plt.title(f\"Caso: {caso} - Top tópicos menos comunes\", \n",
    "            fontsize=16, fontfamily='serif', pad=20, fontweight='bold')\n",
    "    plt.grid(axis='x', linestyle='--', alpha=0.7)\n",
    "    plt.tight_layout()\n",
    "    plt.figtext(0.5, -0.05, f'Estudiantes: {total_alumnos} | Respuestas: {total_alumnos}', \n",
    "            ha='center', fontsize=12)\n",
    "    plt.savefig(f\"{resultados_img}/BERT_Top20_Topicos_Menos_Comunes_d.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(\"Gráficos generados exitosamente.\\n\")\n",
    "\n",
    "# Graficar para Diferencial 1\n",
    "graficar_topicos_agrupados(topic_counts_ind1_dif1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análisis de Tópicos Éticos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import numpy as np\n",
    "import json\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diccionario de tópicos éticos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords_dict = {\n",
    "    \"discriminación\": [\n",
    "        \"exclusión\",\n",
    "        \"inequidad\",\n",
    "        \"sesgo\",\n",
    "        \"injusticia\",\n",
    "        \"prejuicio\",\n",
    "        \"marginación\",\n",
    "        \"desigualdad\",\n",
    "        \"diversidad\",\n",
    "        \"equidad\",\n",
    "        \"estigmatización\"\n",
    "    ],\n",
    "    \"justicia\": [\n",
    "        \"equidad\",\n",
    "        \"imparcialidad\",\n",
    "        \"derechos\",\n",
    "        \"legalidad\",\n",
    "        \"reparación\",\n",
    "        \"necesidad\",\n",
    "        \"deber\",\n",
    "        \"responsabilidad\",\n",
    "        \"honor\",\n",
    "        \"consenso\"\n",
    "    ],\n",
    "    \"igualdad\": [\n",
    "        \"equidad\",\n",
    "        \"justicia\",\n",
    "        \"inclusión\",\n",
    "        \"derechos\",\n",
    "        \"equilibrio\",\n",
    "        \"paridad\",\n",
    "        \"simetría\",\n",
    "        \"respeto\",\n",
    "        \"diversidad\",\n",
    "        \"acceso\"\n",
    "    ],\n",
    "    \"salud\": [\n",
    "        \"bienestar\",\n",
    "        \"prevención\",\n",
    "        \"cuidado\",\n",
    "        \"atención\",\n",
    "        \"sanidad\",\n",
    "        \"nutrición\",\n",
    "        \"ejercicio\",\n",
    "        \"enfermedad\",\n",
    "        \"rehabilitación\",\n",
    "        \"calidad\"\n",
    "    ],\n",
    "    \"transparencia\": [\n",
    "        \"claridad\",\n",
    "        \"honestidad\",\n",
    "        \"acceso\",\n",
    "        \"información\",\n",
    "        \"integridad\",\n",
    "        \"responsabilidad\",\n",
    "        \"confianza\",\n",
    "        \"divulgación\",\n",
    "        \"visibilidad\",\n",
    "        \"rendición\"\n",
    "    ],\n",
    "    \"responsabilidad\": [\n",
    "        \"deber\",\n",
    "        \"obligación\",\n",
    "        \"compromiso\",\n",
    "        \"rendición\",\n",
    "        \"ética\",\n",
    "        \"lealtad\",\n",
    "        \"confianza\",\n",
    "        \"honestidad\",\n",
    "        \"seriedad\",\n",
    "        \"justicia\"\n",
    "    ],\n",
    "    \"derecho\": [\n",
    "        \"ley\",\n",
    "        \"justicia\",\n",
    "        \"libertad\",\n",
    "        \"igualdad\",\n",
    "        \"protección\",\n",
    "        \"responsabilidad\",\n",
    "        \"derechos humanos\",\n",
    "        \"equidad\",\n",
    "        \"defensa\",\n",
    "        \"legislación\"\n",
    "    ],\n",
    "    \"compromiso\": [\n",
    "        \"dedicación\",\n",
    "        \"lealtad\",\n",
    "        \"responsabilidad\",\n",
    "        \"promesa\",\n",
    "        \"seriedad\",\n",
    "        \"altruismo\",\n",
    "        \"confianza\",\n",
    "        \"honor\",\n",
    "        \"solidaridad\",\n",
    "        \"esfuerzo\"\n",
    "    ],\n",
    "    \"privacidad\": [\n",
    "        \"confidencialidad\",\n",
    "        \"protección\",\n",
    "        \"seguridad\",\n",
    "        \"datos\",\n",
    "        \"control\",\n",
    "        \"información\",\n",
    "        \"anonymidad\",\n",
    "        \"secreto\",\n",
    "        \"derechos\",\n",
    "        \"libertad\"\n",
    "    ],\n",
    "    \"seguridad\": [\n",
    "        \"protección\",\n",
    "        \"prevención\",\n",
    "        \"confianza\",\n",
    "        \"integridad\",\n",
    "        \"estabilidad\",\n",
    "        \"defensa\",\n",
    "        \"resiliencia\",\n",
    "        \"alerta\",\n",
    "        \"evaluación\",\n",
    "        \"cuidado\"\n",
    "    ],\n",
    "    \"migracion\": [\n",
    "        \"movimiento\",\n",
    "        \"asilo\",\n",
    "        \"refugiado\",\n",
    "        \"transición\",\n",
    "        \"integración\",\n",
    "        \"diversidad\",\n",
    "        \"cultura\",\n",
    "        \"identidad\",\n",
    "        \"derechos\",\n",
    "        \"nueva vida\"\n",
    "    ],\n",
    "    \"consideracion\": [\n",
    "        \"respeto\",\n",
    "        \"atención\",\n",
    "        \"cuidado\",\n",
    "        \"evaluación\",\n",
    "        \"empatía\",\n",
    "        \"comprensión\",\n",
    "        \"pensamiento\",\n",
    "        \"reflexión\",\n",
    "        \"sopesar\",\n",
    "        \"valoración\"\n",
    "    ],\n",
    "    \"accesibilidad\": [\n",
    "        \"facilidad\",\n",
    "        \"igualdad\",\n",
    "        \"oportunidad\",\n",
    "        \"inclusión\",\n",
    "        \"derechos\",\n",
    "        \"adaptación\",\n",
    "        \"navegabilidad\",\n",
    "        \"atención\",\n",
    "        \"recursos\",\n",
    "        \"participación\"\n",
    "    ],\n",
    "    \"sesgo\": [\n",
    "        \"prejuicio\",\n",
    "        \"tendencia\",\n",
    "        \"influencia\",\n",
    "        \"discriminación\",\n",
    "        \"desviación\",\n",
    "        \"subjetividad\",\n",
    "        \"preferencia\",\n",
    "        \"injusticia\",\n",
    "        \"parcialidad\",\n",
    "        \"opinión\"\n",
    "    ],\n",
    "    \"credibilidad\": [\n",
    "        \"confianza\",\n",
    "        \"validez\",\n",
    "        \"fiabilidad\",\n",
    "        \"autenticidad\",\n",
    "        \"integridad\",\n",
    "        \"reputación\",\n",
    "        \"veracidad\",\n",
    "        \"seriedad\",\n",
    "        \"prestigio\",\n",
    "        \"honor\"\n",
    "    ],\n",
    "    \"solidaridad\": [\n",
    "        \"apoyo\",\n",
    "        \"unión\",\n",
    "        \"cooperación\",\n",
    "        \"compasión\",\n",
    "        \"empatía\",\n",
    "        \"compromiso\",\n",
    "        \"ayuda\",\n",
    "        \"hermandad\",\n",
    "        \"asistencia\",\n",
    "        \"defensa\"\n",
    "    ],\n",
    "    \"social\": [\n",
    "        \"comunidad\",\n",
    "        \"interacción\",\n",
    "        \"relaciones\",\n",
    "        \"cultura\",\n",
    "        \"participación\",\n",
    "        \"organización\",\n",
    "        \"cohesión\",\n",
    "        \"solidaridad\",\n",
    "        \"justicia\",\n",
    "        \"equidad\"\n",
    "    ],\n",
    "    \"etica\": [\n",
    "        \"moral\",\n",
    "        \"valores\",\n",
    "        \"responsabilidad\",\n",
    "        \"integridad\",\n",
    "        \"justicia\",\n",
    "        \"principios\",\n",
    "        \"honestidad\",\n",
    "        \"conducta\",\n",
    "        \"deber\",\n",
    "        \"normas\"\n",
    "    ],\n",
    "    \"consentimiento\": [\n",
    "        \"acuerdo\",\n",
    "        \"permiso\",\n",
    "        \"autonomía\",\n",
    "        \"voluntad\",\n",
    "        \"información\",\n",
    "        \"libertad\",\n",
    "        \"elección\",\n",
    "        \"participación\",\n",
    "        \"responsabilidad\",\n",
    "        \"aceptación\"\n",
    "    ],\n",
    "    \"vulnerabilidad\": [\n",
    "        \"fragilidad\",\n",
    "        \"riesgo\",\n",
    "        \"exposición\",\n",
    "        \"desprotección\",\n",
    "        \"necesidad\",\n",
    "        \"apoyo\",\n",
    "        \"sensibilidad\",\n",
    "        \"desigualdad\",\n",
    "        \"discapacidad\",\n",
    "        \"marginación\"\n",
    "    ],\n",
    "    \"integridad\": [\n",
    "        \"honestidad\",\n",
    "        \"coherencia\",\n",
    "        \"ética\",\n",
    "        \"valores\",\n",
    "        \"responsabilidad\",\n",
    "        \"rectitud\",\n",
    "        \"transparencia\",\n",
    "        \"fiabilidad\",\n",
    "        \"moralidad\",\n",
    "        \"solidaridad\"\n",
    "    ],\n",
    "    \"inclusion\": [\n",
    "        \"diversidad\",\n",
    "        \"acceso\",\n",
    "        \"participación\",\n",
    "        \"igualdad\",\n",
    "        \"respeto\",\n",
    "        \"aceptación\",\n",
    "        \"justicia\",\n",
    "        \"equidad\",\n",
    "        \"cohesión\",\n",
    "        \"solidaridad\"\n",
    "    ],\n",
    "    \"respeto\": [\n",
    "        \"consideración\",\n",
    "        \"dignidad\",\n",
    "        \"valorización\",\n",
    "        \"honor\",\n",
    "        \"cuidado\",\n",
    "        \"aprecio\",\n",
    "        \"tolerancia\",\n",
    "        \"aceptación\",\n",
    "        \"solidaridad\",\n",
    "        \"responsabilidad\"\n",
    "    ],\n",
    "    \"precaucion\": [\n",
    "        \"cuidado\",\n",
    "        \"prevención\",\n",
    "        \"evaluación\",\n",
    "        \"consideración\",\n",
    "        \"riesgo\",\n",
    "        \"seguridad\",\n",
    "        \"atención\",\n",
    "        \"planificación\",\n",
    "        \"responsabilidad\",\n",
    "        \"conservación\"\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lematizar el diccionario de palabras clave\n",
    "nlp = spacy.load(\"es_core_news_md\") \n",
    "\n",
    "ethic_topics_keywords = {}\n",
    "\n",
    "tokenizer = StemmerTokenizer(stem=True) \n",
    "for key, values in keywords_dict.items():\n",
    "    lematizado_key = key  \n",
    "    lematizado_values = [tokenizer(value)[0] for value in values]  \n",
    "    ethic_topics_keywords[lematizado_key] = lematizado_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predecir tópicos éticos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ethic_palabras_clave_en_comentario(comentario):\n",
    "    ponderaciones = {}\n",
    "    doc = nlp(comentario.lower())\n",
    "    \n",
    "    for token in doc:\n",
    "        if token.is_alpha and token.text not in stop_words_custom:\n",
    "            for key, values in keywords_dict.items():\n",
    "                # Verifica coincidencia directa de la lematización\n",
    "                if token.lemma_ in values:\n",
    "                    ponderaciones[key] = ponderaciones.get(key, 0) + 1\n",
    "\n",
    "    # Si no hay coincidencias, agrega \"Sin tópico\"\n",
    "    if not ponderaciones:\n",
    "        ponderaciones[\"Sin tópico\"] = 1\n",
    "\n",
    "    return ponderaciones\n",
    "\n",
    "def predecir_topicos_eticos(comentario):\n",
    "    ponderaciones = ethic_palabras_clave_en_comentario(comentario)\n",
    "    return [topic for topic, peso in ponderaciones.items() if peso > 0]  \n",
    "\n",
    "def predict_ethic_topic(df1, caso):\n",
    "    df1['ETHIC_topicos_ind1'] = \"\"\n",
    "    #df1['ETHIC_topicos_ind2'] = \"\"\n",
    "\n",
    "    #if 'ETHIC_topicos_grup' in df1.columns:\n",
    "    #    df1 = df1.drop(columns=['ETHIC_topicos_grup'])\n",
    "\n",
    "    # Topicos para Ind1 e Ind2\n",
    "    for i, comentario in df1['Respuesta'].items():\n",
    "        topicos = predecir_topicos_eticos(comentario)\n",
    "        df1.at[i, 'ETHIC_topicos_ind1'] = topicos\n",
    "\n",
    "    # Guardar topicos predichos\n",
    "    df1.to_csv(f\"../processed_data/{caso}/ETHIC_Topics_df1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_ethic_topic(df_caso, caso)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gráficos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Graficar === #\n",
    "def procesar_y_graficar_topicos(caso):\n",
    "    # Leer dataframes\n",
    "    df = pd.read_csv(f\"../processed_data/{caso}/ETHIC_Topics_df1.csv\")\n",
    "    total_alumnos = len(df)\n",
    "\n",
    "    # Aplicar estilo de Seaborn\n",
    "    sns.set(style=\"whitegrid\")\n",
    "    \n",
    "    # Extraer y contar tópicos para cada etapa y diferencial\n",
    "    # Expandir las listas en las columnas y convertir a minúsculas\n",
    "    expanded_topics_ind1 = df['ETHIC_topicos_ind1'].apply(lambda x: eval(x) if isinstance(x, str) else x).explode().str.lower()\n",
    "\n",
    "    # Contar las ocurrencias de cada tópico\n",
    "    topic_counts_ind1 = expanded_topics_ind1.value_counts().reset_index()\n",
    "\n",
    "    # Renombrar las columnas\n",
    "    topic_counts_ind1.columns = ['Tópico', 'Frecuencia']\n",
    "\n",
    "    # Unir todos los conteos en un solo DataFrame\n",
    "    all_counts = topic_counts_ind1\n",
    "    all_counts.columns = ['Tópico', 'Frecuencia_Ind1']\n",
    "    \n",
    "    # Reemplazar NaN por 0\n",
    "    all_counts.fillna(0, inplace=True)\n",
    "\n",
    "    # Preparar las frecuencias totales\n",
    "    all_counts['Frecuencia_Total'] = all_counts['Frecuencia_Ind1']\n",
    "    \n",
    "    # Obtener los tópicos y frecuencias\n",
    "    top_words = all_counts['Tópico']\n",
    "    freqs_ind1 = all_counts['Frecuencia_Ind1']\n",
    "\n",
    "    # Posiciones en el eje X\n",
    "    x = range(len(top_words))\n",
    "\n",
    "    # Crear el gráfico de barras agrupadas\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    width = 0.3  # Ancho de las barras\n",
    "    bar_ind1 = plt.bar([p - width for p in x], freqs_ind1, width=width, label='Ind1', color=sns.color_palette(\"Blues\")[2])\n",
    "    \n",
    "    # Añadir etiquetas y leyenda\n",
    "    plt.xlabel('Tópicos (Palabras Clave)', fontsize=14)\n",
    "    plt.ylabel('Frecuencia', fontsize=14, ha='center')\n",
    "    plt.title(f\"Caso: {caso} - Frecuencia de tópicos éticos\", fontsize=16, fontfamily='serif')\n",
    "    plt.xticks(ticks=x, labels=top_words, rotation=90, fontsize=12)\n",
    "    \n",
    "\n",
    "    # Añadir líneas de cuadrícula\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Porcentajes en las barras\n",
    "    porcentajes_ind1 = (freqs_ind1 / total_alumnos) * 100\n",
    "    for i, bar in enumerate(bar_ind1):\n",
    "        plt.text(\n",
    "            bar.get_x() + bar.get_width() / 2,  # Posición X (centro de la barra)\n",
    "            bar.get_height() + 5,  # Desplazamos los textos hacia arriba\n",
    "            f\"{porcentajes_ind1[i]:.1f}%\",  # Frecuencia y porcentaje\n",
    "            ha='center', va='bottom', fontsize=10, color='black', rotation=90\n",
    "        )\n",
    "\n",
    "    # Guardar el gráfico\n",
    "    plt.figtext(0.75, 0.01, f\"Total de respuestas: {total_alumnos}\\nCada respuesta puede tener múltiples tópicos.\", ha=\"center\", fontsize=12)\n",
    "    plt.savefig(f\"../resultados/{caso}/ETHIC_Topics_Dif.png\")\n",
    "    plt.close()\n",
    "    \n",
    "    # Graficar los 10 tópicos más comunes\n",
    "    topico_frecuencia = all_counts[['Tópico', 'Frecuencia_Total']].sort_values(by='Frecuencia_Total', ascending=False).head(10)\n",
    "\n",
    "    # Calcular porcentajes\n",
    "    topico_frecuencia['Porcentaje'] = (topico_frecuencia['Frecuencia_Total'] * 100) / (total_alumnos * 3)\n",
    "\n",
    "    plt.figure(figsize=(16, 6))\n",
    "    bars = plt.barh(topico_frecuencia['Tópico'], topico_frecuencia['Frecuencia_Total'], color='lightblue')\n",
    "\n",
    "    # Añadir etiquetas con los porcentajes al final de las barras\n",
    "    for i, bar in enumerate(bars):\n",
    "        plt.text(\n",
    "            bar.get_width() + 1,  \n",
    "            bar.get_y() + bar.get_height() / 2, \n",
    "            f\"{topico_frecuencia['Porcentaje'].iloc[i]:.1f}%\", \n",
    "            ha='left', va='center', fontsize=10\n",
    "        )\n",
    "\n",
    "    plt.barh(topico_frecuencia['Tópico'], topico_frecuencia['Frecuencia_Total'], color='lightblue')\n",
    "    plt.xlabel('Ocurrencias en comentarios', fontsize=14)\n",
    "    plt.ylabel('Tópico', fontsize=14)\n",
    "    plt.title(f'Caso: {caso} - Tópicos relevantes más comunes', fontfamily='serif', fontsize=16)\n",
    "    plt.figtext(0.5, 0.01, f'Total de respuestas: {total_alumnos}', ha='center', fontsize=10)\n",
    "    plt.gca().invert_yaxis()  # Invertir el eje Y para mostrar el más común arriba\n",
    "    plt.subplots_adjust(bottom=0.15)\n",
    "    plt.savefig(f\"../resultados/{caso}/ETHIC_Top10_Topicos_Dif.png\")\n",
    "    plt.close()\n",
    "\n",
    "    # Graficar los 20 tópicos menos comunes\n",
    "    topico_frecuencia_menor = all_counts[['Tópico', 'Frecuencia_Total']].sort_values(by='Frecuencia_Total').head(20)\n",
    "\n",
    "    # Calcular porcentajes\n",
    "    topico_frecuencia_menor['Porcentaje'] = (topico_frecuencia_menor['Frecuencia_Total'] * 100) / (total_alumnos * 3)\n",
    "\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    bars = plt.barh(topico_frecuencia_menor['Tópico'], topico_frecuencia_menor['Frecuencia_Total'], color='lightblue')\n",
    "    \n",
    "    # Añadir etiquetas con los porcentajes al final de las barras\n",
    "    for i, bar in enumerate(bars):\n",
    "        plt.text(\n",
    "            bar.get_width() + 1,  # Posición X (final de la barra)\n",
    "            bar.get_y() + bar.get_height() / 2,  # Posición Y (centro de la barra)\n",
    "            f\"{topico_frecuencia_menor['Porcentaje'].iloc[i]:.1f}%\",  # Mostrar el porcentaje\n",
    "            ha='left', va='center', fontsize=10\n",
    "        )\n",
    "    \n",
    "    \n",
    "    plt.barh(topico_frecuencia_menor['Tópico'], topico_frecuencia_menor['Frecuencia_Total'], color='lightblue')\n",
    "    plt.xlabel('Ocurrencias en comentarios', fontsize=14)\n",
    "    plt.ylabel('Tópico', fontsize=14)\n",
    "    plt.title(f'Caso: {caso} - Tópicos relevantes menos comunes', fontfamily='serif', fontsize=16)\n",
    "    plt.gca().invert_yaxis()  # Invertir el eje Y para mostrar el menos común arriba\n",
    "    plt.subplots_adjust(bottom=0.15)\n",
    "    plt.figtext(0.5, 0.01, f'Total de respuestas: {total_alumnos}', ha='center', fontsize=10)\n",
    "    plt.savefig(f\"../resultados/{caso}/ETHIC_Top20_Topicos_Menos_Comunes_Dif.png\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "procesar_y_graficar_topicos(caso)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tópicos distintos entre etapas (no aplica, puede ser entre años)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "def BERT_contar_topicos_distintos(df, columna):\n",
    "    # Crear un diccionario para almacenar los resultados\n",
    "    topicos_distintos = 0\n",
    "    topicos_distintos += df[columna].nunique()\n",
    "    \n",
    "    return topicos_distintos\n",
    "\n",
    "def ETHIC_contar_topicos_unicos(df, columna):\n",
    "    columna = df[columna].apply(lambda x: ast.literal_eval(x))\n",
    "    # Filtrar los tópicos únicos que no sean \"Sin tópico\"\n",
    "    all_topicos = [topic for topic_list in columna for topic in topic_list if topic != 'Sin tópico']\n",
    "    return len(set(all_topicos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Topicos distintos entre etapas === #\n",
    "def distinct_topics(caso):\n",
    "    # BERT\n",
    "    df1_BERT = pd.read_csv(f'../processed_data/{caso}/BERT_df1.csv')\n",
    "    df2_BERT = pd.read_csv(f'../processed_data/{caso}/BERT_df2.csv')\n",
    "    # ETHICS\n",
    "    df1_ETHICS = pd.read_csv(f'../processed_data/{caso}/ETHIC_Topics_df1.csv')\n",
    "    df2_ETHICS = pd.read_csv(f'../processed_data/{caso}/ETHIC_Topics_df2.csv')\n",
    "\n",
    "    # Contar tópicos únicos en cada columna: ETHIC_topicos_ind1\tETHIC_topicos_ind2\tETHIC_topicos_grup\n",
    "    print('Realizando conteo de tópicos BERT y ETHIC distintos en cada etapa...')\n",
    "    # Diferencial 1\n",
    "    BERT_ind1_df1 = BERT_contar_topicos_distintos(df1_BERT, 'BERT_topicos_ind1')\n",
    "    BERT_grup_df1 = BERT_contar_topicos_distintos(df1_BERT, 'BERT_topicos_grup')\n",
    "    BERT_ind2_df1 = BERT_contar_topicos_distintos(df1_BERT, 'BERT_topicos_ind2')\n",
    "    # Diferencial 2\n",
    "    BERT_ind1_df2 = BERT_contar_topicos_distintos(df2_BERT, 'BERT_topicos_ind1')\n",
    "    BERT_grup_df2 = BERT_contar_topicos_distintos(df2_BERT, 'BERT_topicos_grup')\n",
    "    BERT_ind2_df2 = BERT_contar_topicos_distintos(df2_BERT, 'BERT_topicos_ind2')\n",
    "\n",
    "    # Diferencial 1\n",
    "    ETHIC_ind1_df1 = ETHIC_contar_topicos_unicos(df1_ETHICS, 'ETHIC_topicos_ind1')\n",
    "    ETHIC_grup_df1 = ETHIC_contar_topicos_unicos(df1_ETHICS, 'ETHIC_topicos_grup')\n",
    "    ETHIC_ind2_df1 = ETHIC_contar_topicos_unicos(df1_ETHICS, 'ETHIC_topicos_ind2')\n",
    "    # Diferencial 2\n",
    "    ETHIC_ind1_df2 = ETHIC_contar_topicos_unicos(df2_ETHICS, 'ETHIC_topicos_ind1')\n",
    "    ETHIC_grup_df2 = ETHIC_contar_topicos_unicos(df2_ETHICS, 'ETHIC_topicos_grup')\n",
    "    ETHIC_ind2_df2 = ETHIC_contar_topicos_unicos(df2_ETHICS, 'ETHIC_topicos_ind2')\n",
    "\n",
    "    print(\"Conteo finalizado\")\n",
    "\n",
    "    print(\"Generación de gráficos...\")  \n",
    "    # Grafico 1, topicos distintos por etapa para BERT\n",
    "    # Diferencial 1\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.bar(['Ind1', 'Grup', 'Ind2'], [BERT_ind1_df1, BERT_grup_df1, BERT_ind2_df1], color=sns.color_palette(\"Blues\")[2])\n",
    "    plt.title('Tópicos BERT Distintos por Etapa, Diferencial 1', fontsize=16)\n",
    "    plt.xlabel('Etapa', fontsize=14)\n",
    "    plt.ylabel('Tópicos Distintos', fontsize=14)\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'../resultados/{caso}/BERT_Distinct_Topics_D1.png')\n",
    "    plt.close()\n",
    "    # Diferencial 2\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.bar(['Ind1', 'Grup', 'Ind2'], [BERT_ind1_df2, BERT_grup_df2, BERT_ind2_df2], color=sns.color_palette(\"Blues\")[2])\n",
    "    plt.title('Tópicos BERT Distintos por Etapa, Diferencial 2', fontsize=16)\n",
    "    plt.xlabel('Etapa', fontsize=14)\n",
    "    plt.ylabel('Tópicos Distintos', fontsize=14)\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'../resultados/{caso}/BERT_Distinct_Topics_D2.png')\n",
    "    plt.close()\n",
    "    # Grafico 2, topicos distintos por etapa para ETHIC \n",
    "    # Diferencial 1\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.bar(['Ind1', 'Grup', 'Ind2'], [ETHIC_ind1_df1, ETHIC_grup_df1, ETHIC_ind2_df1], color=sns.color_palette(\"Greens\")[2])\n",
    "    plt.title('Tópicos ETHIC Distintos por Etapa, Diferencial 1', fontsize=16)\n",
    "    plt.xlabel('Etapa', fontsize=14)\n",
    "    plt.ylabel('Tópicos Distintos', fontsize=14)\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'../resultados/{caso}/ETHIC_Distinct_Topics_D1.png')\n",
    "    plt.close()\n",
    "    # Diferencial 2\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.bar(['Ind1', 'Grup', 'Ind2'], [ETHIC_ind1_df2, ETHIC_grup_df2, ETHIC_ind2_df2], color=sns.color_palette(\"Greens\")[2])\n",
    "    plt.title('Tópicos ETHIC Distintos por Etapa, Diferencial 2', fontsize=16)\n",
    "    plt.xlabel('Etapa', fontsize=14)\n",
    "    plt.ylabel('Tópicos Distintos', fontsize=14)\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'../resultados/{caso}/ETHIC_Distinct_Topics_D2.png')\n",
    "    plt.close()\n",
    "\n",
    "    print(\"Gráficos generados\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distinct_topics(caso)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparación de tópicos éticos entre etapas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Código"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ethic_topics_between_stages(caso):\n",
    "    print(\"=== Comparación de Tópicos Éticos entre Etapas ===\")\n",
    "    df1 = pd.read_csv(f\"../processed_data/{caso}/ETHIC_Topics_df1.csv\")\n",
    "    df2 = pd.read_csv(f\"../processed_data/{caso}/ETHIC_Topics_df2.csv\")\n",
    "    print(\"Generando gráfico...\")\n",
    "    # Contar tópicos en Ind1 e Ind2 para df1\n",
    "    df1['len_ETHIC_topicos_ind1'] = df1['ETHIC_topicos_ind1'].apply(len)\n",
    "    df1['len_ETHIC_topicos_ind2'] = df1['ETHIC_topicos_ind2'].apply(len)\n",
    "    df1['topicos_ind2_mayor'] = df1['len_ETHIC_topicos_ind2'] > df1['len_ETHIC_topicos_ind1']\n",
    "    DF1 = df1['topicos_ind2_mayor'].sum()\n",
    "\n",
    "    # Contar tópicos en Ind1 e Ind2 para df2\n",
    "    df2['len_ETHIC_topicos_ind1'] = df2['ETHIC_topicos_ind1'].apply(len)\n",
    "    df2['len_ETHIC_topicos_ind2'] = df2['ETHIC_topicos_ind2'].apply(len)\n",
    "    df2['topicos_ind2_mayor'] = df2['len_ETHIC_topicos_ind2'] > df2['len_ETHIC_topicos_ind1']\n",
    "    DF2 = df2['topicos_ind2_mayor'].sum()\n",
    "\n",
    "    # Datos para el gráfico\n",
    "    data = {\n",
    "        'Diferencial': ['Diferencial 1', 'Diferencial 2'],\n",
    "        'Frecuencia': [DF1, DF2]\n",
    "    }\n",
    "    df_plot = pd.DataFrame(data)\n",
    "\n",
    "    # Crear el gráfico\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    sns.barplot(x='Diferencial', y='Frecuencia', data=df_plot, palette='viridis')\n",
    "\n",
    "    # Personalizar el gráfico\n",
    "    plt.title(\"Estudiantes con más tópicos éticos en Ind2 que en Ind1, por diferencial\", fontsize=16)\n",
    "    plt.xlabel(\"Diferencial\", fontsize=14)\n",
    "    plt.ylabel(\"Frecuencia\", fontsize=14)\n",
    "    plt.xticks(fontsize=12)\n",
    "    plt.yticks(fontsize=12)\n",
    "\n",
    "    # Mostrar el gráfico\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"../resultados/{caso}/ETHIC_Topicos_Ind2_Mayor_Ind1.png\")\n",
    "    plt.close()\n",
    "    print(\"Gráfico generado exitosamente.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ethic_topics_dependency_between_stages(caso):\n",
    "    print(\"=== Dependencia de Tópicos Éticos entre Etapas ===\")\n",
    "    df1 = pd.read_csv(f\"../processed_data/{caso}/ETHIC_Topics_df1.csv\")\n",
    "    df2 = pd.read_csv(f\"../processed_data/{caso}/ETHIC_Topics_df2.csv\")\n",
    "    print(\"Generando gráfico...\")\n",
    "\n",
    "    # Asegurarse de que las columnas relevantes son listas\n",
    "    df1['ETHIC_topicos_ind1'] = df1['ETHIC_topicos_ind1'].apply(eval)  # Suponiendo que las listas están en formato string\n",
    "    df1['ETHIC_topicos_grup'] = df1['ETHIC_topicos_grup'].apply(eval)  # Suponiendo que las listas están en formato string\n",
    "    df2['ETHIC_topicos_ind2'] = df2['ETHIC_topicos_ind2'].apply(eval)  # Suponiendo que las listas están en formato string\n",
    "\n",
    "    # Contar estudiantes que tienen tópicos en Ind2 que no están en Ind1 pero sí en Grup\n",
    "    def check_dependency(row):\n",
    "        # Tópicos en Ind2 que no están en Ind1 pero están en Grup\n",
    "        return any(topic in row['ETHIC_topicos_grup'] and topic not in row['ETHIC_topicos_ind1'] for topic in row['ETHIC_topicos_ind2'])\n",
    "\n",
    "    df2['tiene_topicos_dep'] = df2.apply(check_dependency, axis=1)\n",
    "    DF_dependency_count = df2['tiene_topicos_dep'].sum()\n",
    "\n",
    "    # Datos para el gráfico\n",
    "    data = {\n",
    "        'Dependencia': ['Dependencia de Tópicos'],\n",
    "        'Frecuencia': [DF_dependency_count]\n",
    "    }\n",
    "    df_plot = pd.DataFrame(data)\n",
    "\n",
    "    # Crear el gráfico\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    sns.barplot(x='Dependencia', y='Frecuencia', data=df_plot, palette='coolwarm')\n",
    "\n",
    "    # Personalizar el gráfico\n",
    "    plt.title(\"Cantidad de Estudiantes con Tópicos en Ind2 no en Ind1 pero en Grup\", fontsize=16)\n",
    "    plt.xlabel(\"Dependencia\", fontsize=14)\n",
    "    plt.ylabel(\"Frecuencia\", fontsize=14)\n",
    "    plt.xticks(fontsize=12)\n",
    "    plt.yticks(fontsize=12)\n",
    "\n",
    "    # Mostrar el gráfico\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"../resultados/{caso}/ETHIC_Topicos_Dependencia_Ind2_no_Ind1_Grup.png\")\n",
    "    plt.close()\n",
    "    print(\"Gráfico generado exitosamente.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gráficos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ethic_topics_between_stages(caso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ethic_topics_dependency_between_stages(caso)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nube de palabras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Código"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def procesar_comentarios(comentarios, tokenizer):\n",
    "    texto = ' '.join(comentarios.dropna())  \n",
    "    tokens = tokenizer(texto)  \n",
    "    return ' '.join(tokens)  \n",
    "\n",
    "def generar_nube_palabras(caso, texto, titulo, colormap='viridis', background_color='white', max_words=200, mask=None, stop_words_custom=None):\n",
    "    wordcloud = WordCloud(\n",
    "        width=800,\n",
    "        height=400,\n",
    "        background_color=background_color,\n",
    "        colormap=colormap,  \n",
    "        max_words=max_words,\n",
    "        contour_color='steelblue',  \n",
    "        contour_width=1,\n",
    "        mask=mask, \n",
    "        stopwords=STOPWORDS.union(stop_words_custom if stop_words_custom else set()) \n",
    "    ).generate(texto)\n",
    "    \n",
    "    # Mostrar la nube de palabras\n",
    "    plt.figure(figsize=(10, 5), facecolor=None)\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis('off')\n",
    "    plt.title(titulo, fontsize=16, color='darkblue', fontfamily='serif')\n",
    "    plt.tight_layout(pad=0)\n",
    "    plt.savefig(f\"../resultados/{caso}/WC_{titulo}.png\", dpi=300)\n",
    "\n",
    "# Función principal para generar nubes de palabras\n",
    "def crear_nubes_palabras(caso, df_diferencial_1, df_diferencial_2, tokenizer, stop_words_custom=None, colormap='plasma', background_color='ivory'):\n",
    "    # Crear nubes de palabras para Diferencial 1\n",
    "    for columna in ['Respuesta']:\n",
    "        texto_procesado = procesar_comentarios(df_diferencial_1[columna], tokenizer)\n",
    "        generar_nube_palabras(caso, texto_procesado, f\"Nube de Palabras para {caso}\", colormap=colormap, background_color=background_color, stop_words_custom=stop_words_custom)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gráficos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "stop_words_custom\n",
    "tokenizer = StemmerTokenizer(stem=True, lemmatize=True)\n",
    "crear_nubes_palabras(caso, df_caso, df_caso, tokenizer=tokenizer, stop_words_custom=stop_words_custom)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frecuencia de aparición de palabras éticas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Código"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cargar_y_preprocesar_comentarios(df_dif1, df_dif2, tokenizer):\n",
    "    columnas_comentarios_dif1 = [\n",
    "        'Respuesta'\n",
    "    ]\n",
    "    \n",
    "    comentarios_dif1 = df_dif1[columnas_comentarios_dif1].fillna('').values.flatten()\n",
    "    #comentarios_dif2 = df_dif2[columnas_comentarios_dif2].fillna('').values.flatten()\n",
    "    #comentarios = pd.concat([pd.Series(comentarios_dif1), pd.Series(comentarios_dif2)], axis=0).values.flatten()\n",
    "    comentarios = comentarios_dif1\n",
    "    comentarios = [str(c) for c in comentarios]\n",
    "    return [' '.join(tokenizer(c)) for c in comentarios]\n",
    "\n",
    "# Leer las palabras éticas desde un archivo\n",
    "def read_ethic_words(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        return set(f.read().splitlines())\n",
    "    \n",
    "# Contar cuantas palabras éticas hay en los comentarios\n",
    "def contar_palabras_etica(df1, df2, tokenizer):\n",
    "    palabras_etica = read_ethic_words('../dictionaries/ethic_words.txt')\n",
    "    comentarios = cargar_y_preprocesar_comentarios(df1, df2, tokenizer)\n",
    "    palabras_etica = [tokenizer(palabra)[0] for palabra in palabras_etica]\n",
    "    contador = Counter()\n",
    "    for comentario in comentarios:\n",
    "        for palabra in comentario.split():\n",
    "            if palabra in palabras_etica:\n",
    "                contador[palabra] += 1\n",
    "                \n",
    "    palabras, frecuencias = zip(*contador.items())\n",
    "    total_comentarios = len(comentarios)\n",
    "\n",
    "    # Calcular porcentajes\n",
    "    porcentajes = [frecuencia * 100 / total_comentarios for frecuencia in frecuencias]\n",
    "\n",
    "    # Crear el DataFrame\n",
    "    df_frecuencias = pd.DataFrame({\n",
    "        'Palabra': palabras,\n",
    "        'Frecuencia': frecuencias,\n",
    "        'Porcentaje': porcentajes\n",
    "    })\n",
    "    # Sort dataframe by Frecuencia & Porcentaje\n",
    "    df_frecuencias.sort_values(by=['Frecuencia', 'Porcentaje'], ascending=[False, False], inplace=True)\n",
    "    # Guardar el DataFrame\n",
    "    df_frecuencias.to_csv(f\"../processed_data/{caso}/ETHIC_WORDS_freq_{caso}.csv\", index=False)\n",
    "\n",
    "    # Graficar\n",
    "    total_estudiantes = df1.shape[0]\n",
    "    \n",
    "    plt.figure(figsize=(50, 30))\n",
    "    ax = sns.barplot(\n",
    "        x='Frecuencia',\n",
    "        y='Palabra',\n",
    "        data=df_frecuencias,\n",
    "        palette='viridis'\n",
    "    )\n",
    "\n",
    "    plt.title(f\"Caso: {caso} - Frecuencia de palabras éticas en comentarios\", fontsize=16, fontfamily='serif')\n",
    "    plt.xlabel('Frecuencia', fontsize=14)\n",
    "    plt.ylabel('Palabras Éticas', fontsize=14)\n",
    "    plt.grid(axis='x', linestyle='--', alpha=0.7)\n",
    "    plt.tight_layout()\n",
    "    plt.figtext(0.75, 0.01, f\"Total de estudiantes: {total_estudiantes} | Total de respuestas: {total_comentarios}\" , wrap=True, horizontalalignment='center', fontsize=12)\n",
    "\n",
    "    # Agregar etiquetas\n",
    "    for i, bar in enumerate(ax.patches):\n",
    "        # Obtener frecuencia y porcentaje directamente del DataFrame ordenado\n",
    "        frecuencia = df_frecuencias.iloc[i]['Frecuencia']\n",
    "        porcentaje = df_frecuencias.iloc[i]['Porcentaje']\n",
    "        \n",
    "        plt.text(\n",
    "            bar.get_width() + 12,  # Ajustar posición horizontal\n",
    "            bar.get_y() + bar.get_height() / 2,  # Centrar verticalmente\n",
    "            f\"{int(frecuencia)} ({porcentaje:.1f}%)\",  # Etiqueta\n",
    "            ha='left', va='center', fontsize=10, color='black'\n",
    "        )\n",
    "\n",
    "\n",
    "    #sns.barplot(x='Frecuencia', y='Palabra', data=df_frecuencias.sort_values(by='Frecuencia', ascending=False), palette='viridis')\n",
    "    plt.savefig(f\"../resultados/{caso}/ETHIC_WORDS_freq_{caso}.png\", dpi=300)\n",
    "\n",
    "\n",
    "    # Graficar TOP 10\n",
    "    top10 = df_frecuencias.head(10)\n",
    "\n",
    "    plt.figure(figsize=(20, 12)) \n",
    "    ax_top10 = sns.barplot(\n",
    "        x='Frecuencia',\n",
    "        y='Palabra',\n",
    "        data=top10,\n",
    "        palette='viridis'\n",
    "    )\n",
    "\n",
    "    plt.title(f\"Caso: {caso} - Top 10 palabras éticas\", fontsize=16, fontfamily='serif')\n",
    "    plt.xlabel('Frecuencia', fontsize=14)\n",
    "    plt.ylabel('Palabras Éticas', fontsize=14)\n",
    "    plt.grid(axis='x', linestyle='--', alpha=0.7)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Agregar etiquetas para el TOP 10\n",
    "    for i, bar in enumerate(ax_top10.patches):\n",
    "        frecuencia = top10.iloc[i]['Frecuencia']\n",
    "        porcentaje = top10.iloc[i]['Porcentaje']\n",
    "        plt.text(\n",
    "            bar.get_width() + 2,  # Posición más ajustada\n",
    "            bar.get_y() + bar.get_height() / 2,\n",
    "            f\"{int(frecuencia)} ({porcentaje:.1f}%)\",\n",
    "            ha='left', va='center', fontsize=10, color='black'\n",
    "        )\n",
    "\n",
    "    plt.figtext(0.75, 0.01, f\"Total de estudiantes: {total_estudiantes} | Total de respuestas: {total_comentarios}\" , wrap=True, horizontalalignment='center', fontsize=12)\n",
    "    plt.savefig(f\"../resultados/{caso}/ETHIC_WORDS_TOP10_{caso}.png\", dpi=300)\n",
    "    \n",
    "    return contador"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gráficos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "stop_words_custom\n",
    "tokenizer = StemmerTokenizer(stem=True, lemmatize=True)\n",
    "contar_palabras_etica(df_caso, df_caso, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conectores más usados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Código"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import spacy\n",
    "import os\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Cargar el modelo de Spacy en español\n",
    "nlp = spacy.load(\"es_core_news_md\")\n",
    "\n",
    "def identificar_conectores(texto):\n",
    "    \"\"\"Identifica conectores en el texto dado.\"\"\"\n",
    "    doc = nlp(texto)\n",
    "    conectores_en_texto = [token.text.lower() for token in doc if token.pos_ in [\"CCONJ\", \"SCONJ\", \"ADP\"]]\n",
    "    return conectores_en_texto\n",
    "\n",
    "def extract_grammar_connectors(df1, df2, caso):\n",
    "    # Leer el archivo de datos\n",
    "    conectores_totales = []\n",
    "\n",
    "    # Extraer conectores de cada columna\n",
    "    Ind1_d1 = df1['Respuesta'].apply(identificar_conectores).tolist()\n",
    "    #Grup_d1 = df1['Comentario - Grup - Diferencial 1'].apply(identificar_conectores).tolist()\n",
    "    #Ind2_d1 = df1['Comentario - Ind2 - Diferencial 1'].apply(identificar_conectores).tolist()\n",
    "\n",
    "    #Ind1_d2 = df2['Comentario - Ind1 - Diferencial 2'].apply(identificar_conectores).tolist()\n",
    "    #Grup_d2 = df2['Comentario - Grup - Diferencial 2'].apply(identificar_conectores).tolist()\n",
    "    #Ind2_d2 = df2['Comentario - Ind2 - Diferencial 2'].apply(identificar_conectores).tolist()\n",
    "\n",
    "    conectores_totales.extend([conector for sublist in Ind1_d1 for conector in sublist])\n",
    "    #conectores_totales.extend([conector for sublist in Grup_d1 for conector in sublist])\n",
    "    #conectores_totales.extend([conector for sublist in Ind2_d1 for conector in sublist])\n",
    "\n",
    "    #conectores_totales.extend([conector for sublist in Ind1_d2 for conector in sublist])\n",
    "    #conectores_totales.extend([conector for sublist in Grup_d2 for conector in sublist])\n",
    "    #conectores_totales.extend([conector for sublist in Ind2_d2 for conector in sublist])\n",
    "\n",
    "    # Calcular la frecuencia de conectores\n",
    "    frecuencia_conectores = Counter(conectores_totales)\n",
    "    df_frecuencia = pd.DataFrame(frecuencia_conectores.items(), columns=['Conectores', 'Frecuencia'])\n",
    "    df_frecuencia = df_frecuencia.sort_values(by='Frecuencia', ascending=False)\n",
    "\n",
    "    # Guardar conectores y sus frecuencias en un JSON\n",
    "    df_frecuencia.to_json('../dictionaries/conectores_frecuencia.json', orient='records')\n",
    "\n",
    "    # Crear el directorio si no existe\n",
    "    os.makedirs(f\"../resultados/{caso}\", exist_ok=True)\n",
    "\n",
    "    # Crear una tabla con Matplotlib\n",
    "    fig, ax = plt.subplots(figsize=(10, 27.5))\n",
    "    ax.axis('off')  \n",
    "    table = ax.table(cellText=df_frecuencia.values, colLabels=df_frecuencia.columns, cellLoc='center', loc='center')\n",
    "    table.auto_set_font_size(False)\n",
    "    table.set_fontsize(10)\n",
    "    table.auto_set_column_width(col=list(range(len(df_frecuencia.columns))))\n",
    "    table.scale(3, 3)  \n",
    "\n",
    "    for (i, j), cell in table.get_celld().items():\n",
    "        if i == 0:  # Encabezados\n",
    "            cell.set_fontsize(12)\n",
    "            cell.set_text_props(weight='bold')\n",
    "            cell.set_facecolor('#cccccc') \n",
    "        # Alternar colores de fondo para mejorar la legibilidad\n",
    "        elif i % 2 == 0:\n",
    "            cell.set_facecolor('#f5f5f5')  # Color gris claro para filas pares\n",
    "        else:\n",
    "            cell.set_facecolor('#ffffff')  # Blanco para filas impares\n",
    "        # Agregar un borde más visible a las celdas\n",
    "        cell.set_edgecolor('black')\n",
    "\n",
    "    total_conectores = df_frecuencia['Frecuencia'].sum()\n",
    "    total_comentarios = len(df1)\n",
    "    total_estudiantes = len(df1) \n",
    "\n",
    "    plt.figtext(0.5, 0.01, f\"Total de estudiantes: {total_estudiantes} | Total de respuestas: {total_comentarios} | Total de conectores: {total_conectores}\", ha=\"center\", fontsize=12)\n",
    "    # Guardar la tabla como imagen\n",
    "    plt.title(f'Caso: {caso} - Frecuencia de Conectores en Comentarios', fontsize=16, fontfamily='serif')\n",
    "    plt.savefig(f\"../resultados/{caso}/Conectores_frecuencia_tabla.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gráficos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "extract_grammar_connectors(df_caso, df_caso, caso)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Justificaciones post conectores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Código"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import spacy\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "nlp = spacy.load(\"es_core_news_md\")\n",
    "\n",
    "def identificar_conectores_y_frases(texto):\n",
    "    doc = nlp(texto)\n",
    "    conectores_y_frases = []\n",
    "    for token in doc:\n",
    "        if token.pos_ in [\"CCONJ\", \"SCONJ\", \"ADP\"]:\n",
    "            frase = ' '.join([t.text.lower() for t in doc[token.i + 1:token.i + 6]])  # Captura hasta 5 palabras después del conector\n",
    "            conectores_y_frases.append((token.text, frase))\n",
    "    return conectores_y_frases\n",
    "\n",
    "def extract_keywords_after_connectors(df1, df2, caso):\n",
    "    conectores_y_frases_totales = []\n",
    "\n",
    "    # Extraer conectores y frases de las columnas de df1 para Diferencial 1\n",
    "    for column in ['Respuesta']:\n",
    "        conectores_y_frases_totales.extend(df1[column].apply(identificar_conectores_y_frases).tolist())\n",
    "\n",
    "    # Extraer conectores y frases de las columnas de df2 para Diferencial 2\n",
    "    #for column in ['Comentario - Ind1 - Diferencial 2', 'Comentario - Grup - Diferencial 2', 'Comentario - Ind2 - Diferencial 2']:\n",
    "    #    conectores_y_frases_totales.extend(df2[column].apply(identificar_conectores_y_frases).tolist())\n",
    "\n",
    "    # Aplanar la lista de listas\n",
    "    conectores_y_frases_totales = [item for sublist in conectores_y_frases_totales for item in sublist]\n",
    "\n",
    "    # Contar frecuencia de conectores\n",
    "    conectores = [item[0] for item in conectores_y_frases_totales]\n",
    "    frecuencia_conectores = Counter(conectores)\n",
    "    conectores_mas_usados = [item[0] for item in frecuencia_conectores.most_common(10)]\n",
    "    frases_relevantes = [frase for conector, frase in conectores_y_frases_totales if conector in conectores_mas_usados]\n",
    "\n",
    "    # Calcular TF-IDF para identificar palabras clave en las frases relevantes\n",
    "    custom_stopwords = list(cargar_stopwords('../dictionaries/stopwords_es.txt'))\n",
    "    vectorizer = TfidfVectorizer(stop_words=custom_stopwords, max_features=30)  \n",
    "    tfidf_matrix = vectorizer.fit_transform(frases_relevantes)\n",
    "\n",
    "    # Obtener palabras clave\n",
    "    palabras_clave = vectorizer.get_feature_names_out()\n",
    "    tfidf_scores = tfidf_matrix.sum(axis=0).A1\n",
    "    keywords = sorted(zip(palabras_clave, tfidf_scores), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Convertir palabras clave en DataFrame\n",
    "    df_keywords = pd.DataFrame(keywords, columns=['Palabra Clave', 'Importancia'])\n",
    "    \n",
    "    # Guardar el DataFrame como CSV\n",
    "    os.makedirs(f\"../resultados/{caso}\", exist_ok=True)\n",
    "    df_keywords.to_csv(f\"../processed_data/{caso}/Palabras_Clave_Despues_Conectores.csv\", index=False)\n",
    "\n",
    "    # Crear un gráfico de tabla para las palabras y su importancia\n",
    "    plt.figure(figsize=(10, 13))\n",
    "    plt.axis('tight')\n",
    "    plt.axis('off')\n",
    "\n",
    "    tabla = plt.table(cellText=df_keywords.values,\n",
    "                      colLabels=df_keywords.columns,\n",
    "                      cellLoc='center',\n",
    "                      loc='center')\n",
    "    tabla.auto_set_font_size(False)\n",
    "    tabla.set_fontsize(12)\n",
    "    tabla.scale(2, 2)\n",
    "\n",
    "    # Estilo de celdas\n",
    "    for i, key in enumerate(df_keywords.index):\n",
    "        for j, col in enumerate(df_keywords.columns):\n",
    "            if i == 0:  # Encabezados\n",
    "                tabla[(i,j)].set_fontsize(12)\n",
    "                tabla[(i,j)].set_text_props(weight='bold')\n",
    "                tabla[(i,j)].set_facecolor('#cccccc')  # Fondo gris claro\n",
    "            # Alternar colores de fondo para mejorar la legibilidad\n",
    "            elif i % 2 == 0:\n",
    "                tabla[(i, j)].set_facecolor('#f5f5f5')  # Color gris claro para filas pares\n",
    "            else:\n",
    "                tabla[(i, j)].set_facecolor('#ffffff')  # Blanco para filas impares\n",
    "            # Agregar un borde más visible a las celdas\n",
    "            tabla[(i, j)].set_edgecolor('black')\n",
    "    \n",
    "    plt.title(f\"Caso: {caso} - Palabras post conectores\", fontsize=14, fontfamily='serif')\n",
    "    plt.figtext(0.5, 0.01, f\"Total de estudiantes: {len(df1)} | Total de respuestas: {len(df1)}\", ha=\"center\", fontsize=12)\n",
    "    plt.savefig(f\"../resultados/{caso}/Conectores_Palabras_Clave.png\", bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "    print(f\"Palabras clave después de conectores guardadas en ../resultados/{caso}/Palabras_Clave_Despues_Conectores.csv\")\n",
    "    return df_keywords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gráficos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Palabras clave después de conectores guardadas en ../resultados/Luis 2023/Palabras_Clave_Despues_Conectores.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Palabra Clave</th>\n",
       "      <th>Importancia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>proyecto</td>\n",
       "      <td>344.173124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>empresa</td>\n",
       "      <td>216.662372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>luis</td>\n",
       "      <td>153.829435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>jefe</td>\n",
       "      <td>147.242434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>debió</td>\n",
       "      <td>89.215905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>seguridad</td>\n",
       "      <td>85.069717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>software</td>\n",
       "      <td>81.704894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>recursos</td>\n",
       "      <td>77.788466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>pruebas</td>\n",
       "      <td>77.454281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ética</td>\n",
       "      <td>67.372283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>responsabilidad</td>\n",
       "      <td>60.156746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>consecuencias</td>\n",
       "      <td>58.681926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>experiencia</td>\n",
       "      <td>55.240445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>caso</td>\n",
       "      <td>54.317181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>riesgos</td>\n",
       "      <td>53.160173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>personas</td>\n",
       "      <td>52.953294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>tiempo</td>\n",
       "      <td>50.670589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ingenieros</td>\n",
       "      <td>49.655304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>cargo</td>\n",
       "      <td>49.563103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>profesional</td>\n",
       "      <td>48.879074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>falta</td>\n",
       "      <td>46.850134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>calidad</td>\n",
       "      <td>46.022295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>condiciones</td>\n",
       "      <td>45.988904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>desarrollo</td>\n",
       "      <td>43.514352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>debería</td>\n",
       "      <td>41.401582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>proyectos</td>\n",
       "      <td>39.273517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>limitaciones</td>\n",
       "      <td>38.614912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>situación</td>\n",
       "      <td>36.468976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>cabo</td>\n",
       "      <td>36.342194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>departamento</td>\n",
       "      <td>34.112555</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Palabra Clave  Importancia\n",
       "0          proyecto   344.173124\n",
       "1           empresa   216.662372\n",
       "2              luis   153.829435\n",
       "3              jefe   147.242434\n",
       "4             debió    89.215905\n",
       "5         seguridad    85.069717\n",
       "6          software    81.704894\n",
       "7          recursos    77.788466\n",
       "8           pruebas    77.454281\n",
       "9             ética    67.372283\n",
       "10  responsabilidad    60.156746\n",
       "11    consecuencias    58.681926\n",
       "12      experiencia    55.240445\n",
       "13             caso    54.317181\n",
       "14          riesgos    53.160173\n",
       "15         personas    52.953294\n",
       "16           tiempo    50.670589\n",
       "17       ingenieros    49.655304\n",
       "18            cargo    49.563103\n",
       "19      profesional    48.879074\n",
       "20            falta    46.850134\n",
       "21          calidad    46.022295\n",
       "22      condiciones    45.988904\n",
       "23       desarrollo    43.514352\n",
       "24          debería    41.401582\n",
       "25        proyectos    39.273517\n",
       "26     limitaciones    38.614912\n",
       "27        situación    36.468976\n",
       "28             cabo    36.342194\n",
       "29     departamento    34.112555"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_keywords_after_connectors(df_caso, df_caso, caso)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ethics_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
