{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ETHIC - Primavera 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Selección de caso\n",
    "\n",
    "* 1) Caso Amanda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Casos disponibles:\n",
      "1. Amanda\n",
      "Caso seleccionado: Amanda\n",
      "Archivo: Procesamient_2023_CD1201_2.xlsx, Año: 2023, Sección: 2\n",
      "Archivo: Procesamient_2023_CD1201_3.xlsx, Año: 2023, Sección: 3\n",
      "Archivo: Procesamient_2023_CD1201_4.xlsx, Año: 2023, Sección: 4\n",
      "Archivo: Procesamient_2023_CD1201_5.xlsx, Año: 2023, Sección: 5\n",
      "Archivo: Procesamient_2023_CD1201_7.xlsx, Año: 2023, Sección: 7\n",
      "Archivo: Procesamient_2023_CD1201_8.xlsx, Año: 2023, Sección: 8\n",
      "Archivo: Procesamient_2023_CD1201_9.xlsx, Año: 2023, Sección: 9\n",
      "Archivo: Procesamient_2024_CD1100_2.xlsx, Año: 2024, Sección: 2\n",
      "Archivo: Procesamient_2024_CD1100_4.xlsx, Año: 2024, Sección: 4\n",
      "Archivo: Procesamient_2024_CD1100_6.xlsx, Año: 2024, Sección: 6\n",
      "Archivo: Procesamient_2024_CD1100_7.xlsx, Año: 2024, Sección: 7\n",
      "Archivo: Procesamient_2024_CD1100_8.xlsx, Año: 2024, Sección: 8\n",
      "\n",
      "Carpeta ya existe: processed_data/Amanda\n",
      "Datos procesados guardados en: processed_data/Amanda/answers_by_secc_Amanda.csv\n",
      "\n",
      "Datos leídos de: processed_data/Amanda/answers_by_secc_Amanda.csv\n"
     ]
    }
   ],
   "source": [
    "from utils.extract_data import process_data\n",
    "from utils.extract_data import read_data\n",
    "\n",
    "caso = process_data()\n",
    "df1, df2 = read_data(caso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.head()\n",
    "df2 = df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análisis Gramatical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se debe ejecutar la celda de ejecutar análisis solo si se desea realizar uno nuevo. De lo contrario basta con ejecutar la celda de graficar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.dependency_tree import ejecutar_analisis\n",
    "ejecutar_analisis(df1, df2, caso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "from utils.dependency_tree import tree_dependency_graphs\n",
    "tree_dependency_graphs(caso)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analisis de Topicos BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento Modelo Bert Topic\n",
    "\n",
    "Solo es necesario ejecutarlo si se desea entrenar nuevamente al modelo con más datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.bertopic_model import *\n",
    "\n",
    "# Crear tokenizer\n",
    "tokenizer = StemmerTokenizer(stem=False, lemmatize=True)\n",
    "\n",
    "# Cargar y preprocesar comentarios\n",
    "comentarios_tokenizados = cargar_y_preprocesar_comentarios(df1, df2, tokenizer)\n",
    "\n",
    "# Entrenar modelo BERTopic\n",
    "entrenar_modelo_bertopic(comentarios_tokenizados)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tópicos BERT\n",
    "\n",
    "Obtener los tópicos encontrados por el modelo BERT. Esta celda se debe ejecutar solo si se desea realizar un nuevo análisis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.bertopic_model import *\n",
    "# Cargar el modelo BERTopic desde el archivo guardado\n",
    "BERT_model = BERTopic.load(\"models/BertTopic_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediccion de topicos (ejecutar si se desea realizar uha nueva)\n",
    "predict_topics(BERT_model, df1, df2, caso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_counts_resultados = contar_topicos(caso)\n",
    "graficar_topicos_agrupados(topic_counts_resultados, 1, BERT_model, caso) \n",
    "graficar_topicos_agrupados(topic_counts_resultados, 2, BERT_model, caso)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análisis de Tópics Éticos\n",
    "\n",
    "La celda para obtener los tópicos éticos solo debe ejecutarse si se desea realizar una nueva predicción."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.ethic_topics_model import predict_ethic_topic\n",
    "predict_ethic_topic(df1, df2, caso)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se obtienen gráficos de los tópicos éticos encontrados, y aquellos que son más y menos comunes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "from utils.ethic_topics_model import procesar_y_graficar_topicos\n",
    "procesar_y_graficar_topicos(caso, 1)\n",
    "procesar_y_graficar_topicos(caso, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tópicos distintos entre etapas\n",
    "\n",
    "Análisis de cuantos topicos distintos se encuentran en las respuestas, diferenciando por etapas y por tópicos BERT y ETHIC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.ethic_words import distinct_topics\n",
    "distinct_topics(caso)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparación de tópicos éticos entre etapas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.ethic_topics_model import ethic_topics_between_stages\n",
    "ethic_topics_between_stages(caso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.ethic_topics_model import ethic_topics_dependency_betweeen_stages\n",
    "ethic_topics_dependency_betweeen_stages(caso)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nubes de palabras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "from utils.bertopic_model import *\n",
    "from utils.wordclouds import *\n",
    "\n",
    "stop_words_custom\n",
    "tokenizer = StemmerTokenizer(stem=True, lemmatize=True)\n",
    "crear_nubes_palabras(caso, df1, df2, tokenizer=tokenizer, stop_words_custom=stop_words_custom)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frecuencia de aparación de palabras éticas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.bertopic_model import *\n",
    "from utils.ethic_words import *\n",
    "\n",
    "stop_words_custom\n",
    "tokenizer = StemmerTokenizer(stem=True, lemmatize=True)\n",
    "contar_palabras_etica(df1, df2, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conectores más usados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Justificación ética post conectores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ethic_unit_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
